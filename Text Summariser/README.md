# Text-Summariser-NLP

The project aims to develop a text summarizer using natural language processing techniques with an extractive approach. The summarizer will analyze a given text and identify the most important sentences based on their relevance to the overall content. The system will use techniques such as sentence parsing, keyword extraction, and scoring algorithms to rank and select the most informative sentences. The resulting summary will provide a concise and coherent representation of the original text, enabling users to quickly grasp the main points without having to read the entire document. This project has the potential to assist in various fields such as news agencies, researchers, and businesses to quickly extract the most significant information from large texts.

## Objectives
1. Condensing large amount of text into a shorter version that retains most important information
2. Saving time and effort
3. Improving information retrieval
4. Improving language processing

## Introduction
Text summarization using NLP involves the automatic generation of a shortened version of a given text document, while still retaining its key information and meaning. This project is based on the application of Natural Language Processing (NLP) techniques, which involves the analysis of the language and structure of the text, to extract important sentences and phrases and form a summary.The project involves several steps, such as preprocessing the text data, identifying important sentences and phrases, and generating the summary.

To achieve this, various NLP techniques can be employed, such as text segmentation, part-of-speech tagging, named entity recognition, word embedding, and machine learning algorithms such as clustering and classification.
## Architecture

The set of ordered stages one should go through from a labeled dataset to creating a classifier that can be applied to new samples is called the NLP pipeline.
The various processes of NLP used are Data Collection -> Text Cleaning -> Preprocessing -> Feature Engineering -> Modeling.

Data Collection: Our text summariser uses a publicly available dataset saved into a text file which is then read by the program.

Preprocessing: It involves text cleaning (removal of symbols, unnecessary spaces and brackets) as well as basic preprocessing where word and sentence tokenization stop word removal and lower casing is done. 

Feature engineering and Modeling: Converting text data to numerical data is feature engineering. The sentences that form a part of the summary in our model are decided using sentence scores which inturn depend on word frequencies. The sentences which have higher sentence scores are given priority to be added to the summary.  

## Dataset used
The dataset used is an article of around 5000 words, obtained from Wikipedia, in .txt format that is uploaded in the session storage of the colab notebook for it to be read by the model.

## Performance and Results
The model summarises a dataset containing around 5000 words to produce an accurate summary of 340 words.

The current model that we have presented is based on word and sentence frequency along with considering the presence of stopwords. It could further be improvised by incorporating the concept of word embeddings, where the meaning of the word is given better importance. The model could also be made capable to handle larger datasets.


## References
Dataset:  https://en.wikipedia.org/wiki/Management

Word-sentence co-ranking for automatic extractive text summarization ,Changjian Fang, Dejun Mu, Zhenghong Deng, Zhiang Wu.

Assessing sentence scoring techniques for extractive text summarization, Rafael Ferreira a, Luciano de Souza Cabral a, Rafael Dueire Lins a, Gabriel Pereira e Silva a, Fred Freitas a, George D.C. Cavalcanti a, Rinaldo Lima a, Steven J. Simske b, Luciano Favaro c

## Project Mentors
  [Dinesh Achalaram Choudhari](https://github.com/dinesh-0808)

## Project Mentees
  [A Shishir](https://github.com/Sheldon-Cooper-314)
  
  [Rajashri Varadaraj](https://github.com/Rjshri)
  
  [Snehankitha Bhukya](https://github.com/SnehankithaBhukya)
  
  [Rishi Diwaker](https://github.com/rishi-diwaker1)

